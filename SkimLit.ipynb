{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "582cd8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries.....\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score,precision_recall_fscore_support\n",
    "from tensorflow.keras.layers import TextVectorization,Embedding\n",
    "import warnings\n",
    "import random\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b7c6a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter warnings.\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b691002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for downloading data.....\n",
    "# !git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
    "# !ls pubmed-rct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b15482",
   "metadata": {},
   "source": [
    "The goal of this model is to classify the sentences which appear in the sequences, like what role each sentences serve in the abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288b4de",
   "metadata": {},
   "source": [
    "## What we're going to do:\n",
    "    ~ Download Dataset\n",
    "    ~ Writing Preprocessing Function to prepare data for modelling\n",
    "    ~ Setup Series of Model Experiment\n",
    "    ~ Make MultiModel Model\n",
    "    ~ Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b458443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the files in the dataset\n",
    "# !ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a059aa",
   "metadata": {},
   "source": [
    "Well we've three files there first one is for development set which is another name for validation data while 2nd and 3rd files contain data for testing and training respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f38c2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all filenames in the directory....\n",
    "# data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\"\n",
    "# filenames = [data_dir + fname for fname in os.listdir(data_dir)]\n",
    "# filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d53d1738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md     dev.txt       test.txt\r\n",
      "SkimLit.ipynb \u001b[34mpubmed-rct\u001b[m\u001b[m    train.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d041b2be",
   "metadata": {},
   "source": [
    "## Preprocessing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "defd92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a function that will preprocess the data\n",
    "def get_lines(fname):\n",
    "    \"\"\"\n",
    "    reads the filename and return the lines of the text as a list\n",
    "    \"\"\"\n",
    "    with open(fname,\"r\") as file:\n",
    "        return file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3217ea7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md     dev.txt       test.txt\r\n",
      "SkimLit.ipynb \u001b[34mpubmed-rct\u001b[m\u001b[m    train.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9465d9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the lines \n",
    "train_lines = get_lines(\"train.txt\")\n",
    "train_lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d55ffe70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89fc85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(filename):\n",
    "  input_lines = get_lines(filename) # get all lines from filename\n",
    "  abstract_lines = \"\" # create an empty abstract\n",
    "  abstract_samples = [] # create an empty list of abstracts\n",
    "  \n",
    "  # Loop through each line in target file\n",
    "  for line in input_lines:\n",
    "    if line.startswith(\"###\"): # check to see if line is an ID line\n",
    "      abstract_id = line\n",
    "      abstract_lines = \"\" # reset abstract string\n",
    "    elif line.isspace(): # check to see if line is a new line\n",
    "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
    "\n",
    "      # Iterate through each line in abstract and count them at the same time\n",
    "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "        line_data = {} # create empty dict to store data from line\n",
    "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
    "        line_data[\"target\"] = target_text_split[0] # get target label\n",
    "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
    "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
    "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
    "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
    "    \n",
    "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
    "      abstract_lines += line\n",
    "  \n",
    "  return abstract_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31baaed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data from files and preprocess it\n",
    "train_samples = preprocess_text(\"train.txt\")\n",
    "val_samples = preprocess_text(\"dev.txt\")\n",
    "test_samples = preprocess_text(\"test.txt\")\n",
    "\n",
    "# checking the length of each sample\n",
    "len(train_samples),len(val_samples),len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40ccdbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180035</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>for the absolute change in percent atheroma vo...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180036</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>for pav , a significantly greater percentage o...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180037</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>both strategies had acceptable side effect pro...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180038</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>compared with standard statin monotherapy , th...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180039</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>( plaque regression with cholesterol absorptio...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180040 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             target                                               text  \\\n",
       "0         OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
       "1           METHODS  a total of @ patients with primary knee oa wer...   \n",
       "2           METHODS  outcome measures included pain reduction and i...   \n",
       "3           METHODS  pain was assessed using the visual analog pain...   \n",
       "4           METHODS  secondary outcome measures included the wester...   \n",
       "...             ...                                                ...   \n",
       "180035      RESULTS  for the absolute change in percent atheroma vo...   \n",
       "180036      RESULTS  for pav , a significantly greater percentage o...   \n",
       "180037      RESULTS  both strategies had acceptable side effect pro...   \n",
       "180038  CONCLUSIONS  compared with standard statin monotherapy , th...   \n",
       "180039  CONCLUSIONS  ( plaque regression with cholesterol absorptio...   \n",
       "\n",
       "        line_number  total_lines  \n",
       "0                 0           11  \n",
       "1                 1           11  \n",
       "2                 2           11  \n",
       "3                 3           11  \n",
       "4                 4           11  \n",
       "...             ...          ...  \n",
       "180035            7           11  \n",
       "180036            8           11  \n",
       "180037            9           11  \n",
       "180038           10           11  \n",
       "180039           11           11  \n",
       "\n",
       "[180040 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert them into pandas data-frame\n",
    "train_df = pd.DataFrame(train_samples)\n",
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)\n",
    "\n",
    "# check out the head of train df\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6c074c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METHODS        59353\n",
       "RESULTS        57953\n",
       "CONCLUSIONS    27168\n",
       "BACKGROUND     21727\n",
       "OBJECTIVE      13839\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the destribution of the target values...\n",
    "train_df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d55762c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's visulize it...\n",
    "train_df[\"target\"].value_counts().plot(kind=\"bar\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ff79a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the sentences from data-frame line X values\n",
    "train_sentences = train_df[\"text\"].tolist()\n",
    "val_sentences = val_df[\"text\"].tolist()\n",
    "test_sentences = test_df[\"text\"].tolist()\n",
    "\n",
    "# viewing couple of few lines...\n",
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81afcb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 4, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the \"Target\" Y values and convert them into One-Hot-Encoder\n",
    "encoder = LabelEncoder()\n",
    "train_labels = encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
    "test_labels = encoder.transform(test_df[\"target\"].to_numpy())\n",
    "val_labels = encoder.transform(val_df[\"target\"].to_numpy())\n",
    "\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60429a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c34b101",
   "metadata": {},
   "source": [
    "## Model Experiments:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657c7280",
   "metadata": {},
   "source": [
    "## Model 0 : BaseLine Model\n",
    "\n",
    "our first baseline model will be scikit-learn Naive Bayes Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de29ceb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;model&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;model&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('model', MultinomialNB())])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline model\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\",TfidfVectorizer()),\n",
    "    (\"model\",MultinomialNB())\n",
    "])\n",
    "\n",
    "# fitting the model on data....\n",
    "model_0.fit(train_sentences,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "836f3e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.1832384482987"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate baseline model...\n",
    "model_0.score(val_sentences,val_labels) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c048135",
   "metadata": {},
   "source": [
    "## Model Perfomance Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d07b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a function that will evaluate our model performance\n",
    "def calculate_results(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    This function will take two parameters and will return the Model Accuracy,Precision,Recall and Support.\n",
    "    \"\"\"\n",
    "    model_accuracy = accuracy_score(y_true,y_pred) * 100\n",
    "    model_precision,model_recall,model_fscore,_ = precision_recall_fscore_support(y_true,y_pred,\n",
    "                                                                                  average=\"weighted\")\n",
    "    results = {\"Accuracy\" : model_accuracy,\n",
    "              \"Precision\" : model_precision,\n",
    "              \"Recall\" : model_recall,\n",
    "              \"Fscore\" : model_fscore}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58483994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3, ..., 4, 4, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction on baseline model\n",
    "baseline_pred = model_0.predict(val_sentences)\n",
    "baseline_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0176a45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 72.1832384482987,\n",
       " 'Precision': 0.7186466952323352,\n",
       " 'Recall': 0.7218323844829869,\n",
       " 'Fscore': 0.6989250353450294}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's calculate the results...\n",
    "baseline_results = calculate_results(val_labels,baseline_pred)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef92cdf",
   "metadata": {},
   "source": [
    "Wow! look like our model has achieved accuracy of 72.1% not bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e2f4b",
   "metadata": {},
   "source": [
    "## Prepare data for deep learning models...\n",
    "\n",
    "We've to convert our data into a shape that is suitable for deep learning models.\n",
    "First we'll tokenize our data and then embbed it and finally feed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d617916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.338269273494777"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's find out the average sentence length\n",
    "sent_len = [len(sentence.split()) for sentence in train_sentences]\n",
    "avg_len = sum(sent_len)/len(train_sentences)\n",
    "avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e395822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the length for output_sequence\n",
    "output_seq_len = int(np.percentile(sent_len,95))\n",
    "output_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d32f8405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 20:17:07.783723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# max tokens...\n",
    "max_tokens = 68000\n",
    "\n",
    "# make first tokenizer layer\n",
    "text_vectorizer = TextVectorization(max_tokens=max_tokens,\n",
    "                                   output_sequence_length = output_seq_len,)\n",
    "\n",
    "# adapt it to the train data...\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "418dd89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence : further studies are needed to clarify what mechanism underlies the cardiovascular benefit of metformin treatment .\n",
      "\n",
      "Vectorizer Sentence : [[  298   202    58   440     6  3920  2731  1386 42846     2   323   398\n",
      "      4   886    19     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# check out the vectorizer\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original Sentence : {random_sentence}\\n\")\n",
    "print(f\"Vectorizer Sentence : {text_vectorizer([random_sentence])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf769206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words in the Vocabulary : 64841\n",
      "\n",
      "Top five words :\n",
      " ['', '[UNK]', 'the', 'and', 'of']\n",
      "\n",
      "Bottom five words : \n",
      " ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
     ]
    }
   ],
   "source": [
    "# find out the vocabulary from data...\n",
    "vocab = text_vectorizer.get_vocabulary()\n",
    "print(f\"Total Words in the Vocabulary : {len(vocab)}\\n\")\n",
    "print(f\"Top five words :\\n {vocab[:5]}\\n\")\n",
    "print(f\"Bottom five words : \\n {vocab[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd0248c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "185c0710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence : \n",
      "groups were well-matched at baseline .\n",
      "\n",
      "Embedd Sentence : \n",
      " [[[ 0.0064976  -0.00027972  0.01783203 ...  0.03910864 -0.02880656\n",
      "   -0.00154952]\n",
      "  [ 0.04512023 -0.03658974 -0.01384103 ... -0.04305023 -0.04460275\n",
      "    0.00724311]\n",
      "  [-0.03848246  0.04813076 -0.00628006 ...  0.00268622  0.00378869\n",
      "    0.01529058]\n",
      "  ...\n",
      "  [-0.04049016  0.04651656  0.00995301 ... -0.0135052   0.02393161\n",
      "   -0.02561928]\n",
      "  [-0.04049016  0.04651656  0.00995301 ... -0.0135052   0.02393161\n",
      "   -0.02561928]\n",
      "  [-0.04049016  0.04651656  0.00995301 ... -0.0135052   0.02393161\n",
      "   -0.02561928]]]\n"
     ]
    }
   ],
   "source": [
    "# Create Embedd Layer for richer representation for our token numbers...\n",
    "embed_layer = Embedding(input_dim = len(vocab),\n",
    "                       output_dim =128,\n",
    "                       embeddings_initializer=\"uniform\",\n",
    "                       input_length=55,\n",
    "                       name=\"Default_Embedding\")\n",
    "\n",
    "# check out the Embedding layer\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original Sentence : \\n{random_sentence}\\n\")\n",
    "print(f\"Embedd Sentence : \\n {embed_layer(text_vectorizer([random_sentence]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76b23bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset as fast as possible \n",
    "# let's convert our data into tensors...\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences,train_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences,val_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2f23b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert them into the batches and prefetch for fast load on GPU\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b36463a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the train dataset\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901145bb",
   "metadata": {},
   "source": [
    "## Model 1 : Cov1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "acbad219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv1D_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_3 (TextV  (None, 55)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " Default_Embedding (Embeddin  (None, 55, 128)          8299648   \n",
      " g)                                                              \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 55, 64)            41024     \n",
      "                                                                 \n",
      " global_average_pooling1d_6   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,340,997\n",
      "Trainable params: 8,340,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the first model we're going to build is 1-dimensional Convolutional Neural Network...\n",
    "\n",
    "# create input layer\n",
    "inputs = layers.Input(shape = (1,),dtype=tf.string)\n",
    "\n",
    "# text vectorization layer...\n",
    "x = text_vectorizer(inputs)\n",
    "\n",
    "# Embedd layer...\n",
    "x = embed_layer(x)\n",
    "\n",
    "# conv1d layer\n",
    "x = layers.Conv1D(64,kernel_size=5,padding=\"same\",activation=\"relu\")(x)\n",
    "\n",
    "# add the average pool layer....\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "# the output layer\n",
    "outputs = layers.Dense(num_classes,activation=\"softmax\")(x)\n",
    "\n",
    "# build the model...\n",
    "model_1 = tf.keras.Model(inputs,outputs,name=\"Conv1D_Model\")\n",
    "\n",
    "# compile the model\n",
    "model_1.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer = tf.keras.optimizers.Adam(),\n",
    "               metrics = [\"accuracy\"])\n",
    "# model_1 summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3eccd23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 18s 32ms/step - loss: 1.2597 - accuracy: 0.4693 - val_loss: 1.1953 - val_accuracy: 0.5193\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 18s 32ms/step - loss: 1.2168 - accuracy: 0.4859 - val_loss: 1.2028 - val_accuracy: 0.5066\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 18s 32ms/step - loss: 1.1391 - accuracy: 0.5271 - val_loss: 1.0939 - val_accuracy: 0.5535\n"
     ]
    }
   ],
   "source": [
    "# fitting the model to data.....\n",
    "history_1 = model_1.fit(train_dataset,\n",
    "                        steps_per_epoch=int(0.1 * len(train_dataset)),\n",
    "                       epochs=3,\n",
    "                       validation_data=val_dataset,\n",
    "                       validation_steps = int(0.1 * len(val_dataset)),\n",
    "                       callbacks =[tf.keras.callbacks.EarlyStopping(patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1a90bc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.18343605, 0.38190085, 0.15638387, 0.19374837, 0.08453083],\n",
       "       [0.08545598, 0.42853585, 0.18297142, 0.06990896, 0.23312773],\n",
       "       [0.1174807 , 0.58200574, 0.08634534, 0.13393417, 0.08023404],\n",
       "       ...,\n",
       "       [0.02719704, 0.23772095, 0.23112655, 0.04485426, 0.4591012 ],\n",
       "       [0.02557393, 0.13115437, 0.3423103 , 0.05000559, 0.4509558 ],\n",
       "       [0.36048737, 0.53199804, 0.057882  , 0.04449636, 0.00513617]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to make prediction with our model\n",
    "model_1_probs = model_1.predict(val_dataset)\n",
    "model_1_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7478170b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([1, 1, 1, ..., 4, 4, 1])>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert proeb probs into labels\n",
    "model_1_preds = tf.argmax(model_1_probs,axis=1)\n",
    "model_1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ba558291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 56.66953528399311,\n",
       " 'Precision': 0.5947800425516722,\n",
       " 'Recall': 0.5666953528399311,\n",
       " 'Fscore': 0.5434600133264164}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate our model performance....\n",
    "model_1_results = calculate_results(val_labels,model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1083971",
   "metadata": {},
   "source": [
    "## Model 2 : Conv1D with Character Embeddings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "551d3ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function that will split sentences into characters...\n",
    "def split_sentences(sentence):\n",
    "    return \" \".join(list(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b824fa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .\n"
     ]
    }
   ],
   "source": [
    "# split sentences into characters....\n",
    "train_char = [split_sentences(sentence) for sentence in train_sentences]\n",
    "val_char = [split_sentences(sentence) for sentence in val_sentences]\n",
    "test_char = [split_sentences(sentence) for sentence in test_sentences]\n",
    "\n",
    "print(train_char[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bf791e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.3662574983337"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average character length....\n",
    "char_len = [len(sentence) for sentence in train_sentences]\n",
    "mean_char = np.mean(char_len)\n",
    "mean_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "68621153",
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U379'), dtype('<U279')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [102]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpercentile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_char\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m95\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m output_seq_len\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpercentile\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/numpy/lib/function_base.py:4134\u001b[0m, in \u001b[0;36mpercentile\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[1;32m   4132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[1;32m   4133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentiles must be in the range [0, 100]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 4134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_quantile_unchecked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/numpy/lib/function_base.py:4383\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[1;32m   4375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantile_unchecked\u001b[39m(a,\n\u001b[1;32m   4376\u001b[0m                         q,\n\u001b[1;32m   4377\u001b[0m                         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4380\u001b[0m                         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4381\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   4382\u001b[0m     \u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4383\u001b[0m     r, k \u001b[38;5;241m=\u001b[39m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4384\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_quantile_ureduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4385\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4386\u001b[0m \u001b[43m                    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4387\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4388\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4389\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n\u001b[1;32m   4391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mreshape(q\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m k)\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/numpy/lib/function_base.py:3702\u001b[0m, in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3699\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3700\u001b[0m     keepdim \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m a\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m-> 3702\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3703\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r, keepdim\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/numpy/lib/function_base.py:4552\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[0;34m(a, q, axis, out, overwrite_input, method)\u001b[0m\n\u001b[1;32m   4550\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4551\u001b[0m         arr \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m-> 4552\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_quantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4553\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4554\u001b[0m \u001b[43m                   \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4555\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4556\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/numpy/lib/function_base.py:4669\u001b[0m, in \u001b[0;36m_quantile\u001b[0;34m(arr, quantiles, axis, method, out)\u001b[0m\n\u001b[1;32m   4667\u001b[0m     result_shape \u001b[38;5;241m=\u001b[39m virtual_indexes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m (arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4668\u001b[0m     gamma \u001b[38;5;241m=\u001b[39m gamma\u001b[38;5;241m.\u001b[39mreshape(result_shape)\n\u001b[0;32m-> 4669\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_lerp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprevious\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4670\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4671\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4672\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(slices_having_nans):\n\u001b[1;32m   4674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4675\u001b[0m         \u001b[38;5;66;03m# can't write to a scalar\u001b[39;00m\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/numpy/lib/function_base.py:4486\u001b[0m, in \u001b[0;36m_lerp\u001b[0;34m(a, b, t, out)\u001b[0m\n\u001b[1;32m   4472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lerp\u001b[39m(a, b, t, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   4473\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4474\u001b[0m \u001b[38;5;124;03m    Compute the linear interpolation weighted by gamma on each point of\u001b[39;00m\n\u001b[1;32m   4475\u001b[0m \u001b[38;5;124;03m    two same shape array.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4484\u001b[0m \u001b[38;5;124;03m        Output array.\u001b[39;00m\n\u001b[1;32m   4485\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4486\u001b[0m     diff_b_a \u001b[38;5;241m=\u001b[39m \u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4487\u001b[0m     \u001b[38;5;66;03m# asanyarray is a stop-gap until gh-13105\u001b[39;00m\n\u001b[1;32m   4488\u001b[0m     lerp_interpolation \u001b[38;5;241m=\u001b[39m asanyarray(add(a, diff_b_a \u001b[38;5;241m*\u001b[39m t, out\u001b[38;5;241m=\u001b[39mout))\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U379'), dtype('<U279')) -> None"
     ]
    }
   ],
   "source": [
    "output_seq_len = int(np.percentile(train_char,95))\n",
    "output_seq_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79403a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
